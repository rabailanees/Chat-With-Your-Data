{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E6430\\AppData\\Local\\Temp\\ipykernel_1264\\2052152661.py:10: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "e:\\Projects\\portfolio_chatbot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector size: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of vectors_np: (8, 384)\n",
      "Vectors added to FAISS index successfully!\n",
      "FAISS vector store initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the PDF document\n",
    "loader = PyPDFLoader(\"./data/document.pdf\")  # Use the correct path to your PDF\n",
    "documents = loader.load()\n",
    "\n",
    "# Step 2: Split the document\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Step 3: Create embeddings and FAISS index\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Get the actual vector size from the embeddings\n",
    "sample_vector = embeddings.embed_query(\"test\")\n",
    "vector_size = len(sample_vector)\n",
    "print(f\"Embedding vector size: {vector_size}\")\n",
    "\n",
    "# Create FAISS index with the correct vector size\n",
    "faiss_index = faiss.IndexFlatL2(vector_size)\n",
    "\n",
    "# Step 4: Add vectors to FAISS index\n",
    "vectors = [embeddings.embed_query(doc.page_content) for doc in texts]\n",
    "vectors_np = np.array(vectors, dtype='float32')  # Ensure float32 type for FAISS\n",
    "print(f\"Shape of vectors_np: {vectors_np.shape}\")\n",
    "\n",
    "# Add vectors to the index\n",
    "faiss_index.add(vectors_np)\n",
    "print(\"Vectors added to FAISS index successfully!\")\n",
    "\n",
    "# Step 5: Create a docstore and index_to_docstore_id mapping\n",
    "docstore = InMemoryDocstore({str(i): texts[i] for i in range(len(texts))})\n",
    "index_to_docstore_id = {i: str(i) for i in range(len(texts))}\n",
    "\n",
    "# Step 6: Initialize the FAISS vector store\n",
    "vectordb = FAISS(\n",
    "    index=faiss_index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id,\n",
    "    embedding_function=embeddings.embed_query\n",
    ")\n",
    "\n",
    "print(\"FAISS vector store initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved to faiss_index.index\n",
      "Metadata saved to embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "faiss_index_file = \"faiss_index.index\"\n",
    "embeddings_file = \"embeddings.pkl\"\n",
    "\n",
    "# Save the FAISS index\n",
    "faiss.write_index(faiss_index, faiss_index_file)\n",
    "print(f\"FAISS index saved to {faiss_index_file}\")\n",
    "\n",
    "# Save the metadata\n",
    "with open(embeddings_file, \"wb\") as f:\n",
    "    pickle.dump(texts, f)\n",
    "print(f\"Metadata saved to {embeddings_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. It's nice to meet you. Is there something I can help you with or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "groq_api_key = \"YOUR_GROQ_API_KEY\"\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0.3,\n",
    "    api_key=groq_api_key,\n",
    ")\n",
    "\n",
    "answer = llm.invoke(\"Hello there!\")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_qa_retrieval_chain(chain, query):\n",
    "    response = chain.invoke({'query': query})\n",
    "    \n",
    "    result_str = f'Query: {response[\"query\"]}\\n\\n'\n",
    "    result_str += f'Result: {response[\"result\"]}\\n\\n'\n",
    "    \n",
    "    relevant_docs = response['source_documents']\n",
    "    for i in range(len(relevant_docs)):\n",
    "        result_str += f'Relevant Doc {i+1}:\\n'\n",
    "        result_str += relevant_docs[i].page_content + '\\n'\n",
    "        result_str += str(relevant_docs[i].metadata) + '\\n\\n'\n",
    "    \n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, \n",
    "just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. \n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={'prompt': QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is her educational background?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is her educational background?\n",
      "\n",
      "Result: Rabail Anees is pursuing a Bachelor of Data Science at the University of the Punjab, Lahore, from 2021-2025. Relevant coursework includes Programming, Advanced Statistics, Machine Learning, and Artificial Intelligence.\n",
      "\n",
      "Relevant Doc 1:\n",
      "● DevelopedaresponsivefrontendinterfaceusingHTMLandCSS.● PortfolioWebsite:● BuiltaresponsivepersonalportfoliousingTailwindCSSandJavaScript.\n",
      "AwardsandAchievements\n",
      "● Winner:DataAnalyticscompetitionatNutec2024.● Top5Finalist:AIcompetitionatNAScon2024.● Participatedinspeedprogrammingcompetitions,including:● CodeBees.● Softec.● CodeFest.\n",
      "Certifications\n",
      "● MicrosoftOfficeSpecialist(MOS).● IntroductiontoFrontendDevelopment(Coursera).\n",
      "CommunityWork\n",
      "{'source': './data/document.pdf', 'page': 2}\n",
      "\n",
      "Relevant Doc 2:\n",
      "● DataAnalysisandVisualization:Excel,Plotly, Matplotlib,Seaborn,NumPy.● DatabaseManagement:MySQLWorkbench,SQLite3,SQLServer.● AIandMachineLearning:Pandas,Scikit-learn.\n",
      "EducationalBackground\n",
      "BachelorofDataScienceUniversityofthePunjab,Lahore| 2021- 2025● RelevantCoursework:Programming,AdvancedStatistics,MachineLearning,ArtificialIntelligence.\n",
      "Projects\n",
      "DataScience/MachineLearningProjects\n",
      "{'source': './data/document.pdf', 'page': 1}\n",
      "\n",
      "Relevant Doc 3:\n",
      "Projects\n",
      "DataScience/MachineLearningProjects\n",
      "● BipolarDisorderStageIdentification:● DevelopedaKNNclassifierusingPakistanidatatoclassifytheintensityofbipolardisorderaccurately.● FashionRecommendationSystem:● UtilizedResNet-50andKNNtobuildasystemidentifyingthetop5closestmatches.● HousePricePredictor:● Analyzedvariousregressionmodelstopredicthousepricingdatasets.\n",
      "WebScrapingProject\n",
      "● ScrapedDisneymoviesdatausingBeautifulSoupfordatacollectionandanalysis.\n",
      "FrontendDevelopmentProjects\n",
      "{'source': './data/document.pdf', 'page': 1}\n",
      "\n",
      "Relevant Doc 4:\n",
      "RabailAnees\n",
      "AspiringDataScientist● Skilledattransformingcomplexdatasetsintoactionableinsights.● ExperiencedinAI,MachineLearning,andAnalytics.● Adaptabletoworkingsoloorincross-functionalteams.\n",
      "ContactInformation:● Phone:03074414085● Email:rabailanees@gmail.com● LinkedIn:https://www.linkedin.com/in/rabail-anees-2a9182241/\n",
      "WorkExperience\n",
      "BackendDeveloper|AmericanClient\n",
      "{'source': './data/document.pdf', 'page': 0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = process_qa_retrieval_chain(qa_chain, query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
